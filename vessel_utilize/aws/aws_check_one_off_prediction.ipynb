{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Sagemaker\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.session import s3_input, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Sagemaker: Define bucket's name for project\n",
    "bucket = 'ls-aishub-inflated'\n",
    "my_region = boto3.session.Session().region_name\n",
    "print(f\"Region: {my_region}\")\n",
    "\n",
    "# Get permission to read from S3 buckets\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "print(f\"Role: {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle5 as pickle\n",
    "\n",
    "print(f\"Packages' versions:\")\n",
    "print(f\"\\tScikit-learn: {sklearn.__version__}\")\n",
    "print(f\"\\tNumpy: {np.__version__}\")\n",
    "print(f\"\\tPandas: {pd.__version__}\")\n",
    "print(f\"\\tXGBoost: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dev_csv(target, data='containershipdb_vu_devset.csv', **kwargs):\n",
    "    print(f\"Load data...\")\n",
    "    location = f's3://{bucket}/experimental_data/{data}'\n",
    "    usecols_static = [\n",
    "        \"ais_dim_a\",\n",
    "        \"ais_dim_b\",\n",
    "        \"ais_dim_c\",\n",
    "        \"ais_dim_d\",\n",
    "        \"draught_fact\",\n",
    "    ] + [target]\n",
    "    df = pd.read_csv(\n",
    "        location,\n",
    "        header=0,\n",
    "        usecols=usecols_static,\n",
    "        **kwargs,\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_example_df(target):\n",
    "    \"\"\"Create example df for checking model prediction\n",
    "    Model fitted on pandas data frame, due that convert to df\n",
    "    \"\"\"\n",
    "    # Get instances from DEV set\n",
    "    rows = [0, 600, 800]\n",
    "    df = load_dev_csv(target=target, nrows=1000).iloc[rows, :]\n",
    "\n",
    "    # With 1 data example\n",
    "    example_df_1 = df.iloc[[0], :-1]\n",
    "    y_true_1 = df.iloc[[0], -1].to_list()\n",
    "    # With 2 data examples\n",
    "    example_df_2 = df.iloc[[1, 2], :-1]\n",
    "    y_true_2 = df.iloc[[1, 2], -1].to_list()\n",
    "\n",
    "    examples = [(example_df_1, y_true_1), (example_df_2, y_true_2)]\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(bucket, model_name):\n",
    "    print(f\"Load model...\")\n",
    "    model_path = f\"models/vessel-utilization/{model_name}/model.pkl\"\n",
    "    model = \"model.pkl\"\n",
    "    \n",
    "    s3client = boto3.client('s3')\n",
    "    s3client.download_file(bucket, model_path, model)\n",
    "\n",
    "    with open(model, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    \"\"\"Mean absolute percentage error regression loss.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.metrics import mean_absolute_percentage_error\n",
    "    >>> y_true = np.array([3, -0.5, 2, 7])\n",
    "    >>> y_pred = np.array([2.5, 0.0, 2, 8])\n",
    "    0.3273809523809524...\n",
    "\n",
    "    >>> y_true = np.array([1.0, -1.0, 2, -2])\n",
    "    >>> y_pred = np.array([0.7, -0.7, 1.4, -1.4])\n",
    "    >>> mean_absolute_percentage_error(y_true, y_pred)\n",
    "    0.30000000000000004...\n",
    "    \"\"\"\n",
    "    # Epsilon: is an arbitrary small yet strictly positive numbe\n",
    "    # to avoid undefined results when y is zero\n",
    "    epsilon = np.finfo(np.float64).eps\n",
    "    ape = np.abs(y_pred - y_true) / np.maximum(np.abs(y_true), epsilon)\n",
    "    return np.average(ape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_example_df(model, target):\n",
    "    examples = make_example_df(target=target)\n",
    "    for e in examples:\n",
    "        print(f\"\\nTest example w/ {len(e[0])} instances:\")\n",
    "        print(e[0])\n",
    "        # Make prediction\n",
    "        prediction = model.predict(e[0])\n",
    "        mare = mape(e[1], prediction)\n",
    "        # Print out\n",
    "        print(f\"\\nReal Value: {e[1]}\")\n",
    "        print(f\"Predicted Value: {list(prediction)}\")\n",
    "        print(f\"Mean Absolute Ratio Error: {mare}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(target=None):\n",
    "    \"\"\"Checks a one-off prediction using the trained model.\n",
    "\n",
    "    Args:\n",
    "        * model_name (str): Folder's  name for separatly saved model.\\\n",
    "            Defaults to None.\n",
    "    \"\"\"\n",
    "    print(f\"--------------- START: Check an one-off prediction ----------------\")\n",
    "    if target is None:\n",
    "        print(f\"No target's name...\")\n",
    "        pass\n",
    "    \n",
    "    elif  target == \"vu_estimated\":\n",
    "        print(f\"Target is: <{target}>\")\n",
    "        model_name = \"XGBRegressor-vu_estimated_0c1914e51e754b3893110f91279301f5\"\n",
    "    \n",
    "    elif target == \"teu_estimated\":\n",
    "        print(f\"Target is: <{target}>\")\n",
    "        model_name = \"XGBRegressor-teu_estimated_9ffee2d3fa3d469ea7bfc9df7e5d317f\"\n",
    "        \n",
    "        \n",
    "    model = load_model(bucket=bucket, model_name=model_name)\n",
    "    predict_example_df(model, target)\n",
    "    print(f\"!!! DONE: an one-off prediction passed !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test perdiction for <vu_estimated>\n",
    "main(target=\"vu_estimated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test perdiction for <teu_estimated>\n",
    "main(target=\"teu_estimated\")"
   ]
  }
 ]
}